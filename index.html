<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Affective-Computing</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link href="style.css" rel="stylesheet">
    </head>
    <body>
        <main class="container">
            <h1>Affective Computing</h1>
    
            <section>
                <h5>"Maschinen können niemals menschliche Emotionen verarbeiten, 
                    geschweige denn, sie imitieren!" </h5>
                <p>
                    Das ist oft einer der ersten Gedanken, der Menschen beim Gedanken 
                    an eine Zukunft in enger Verbindung mit Künstlicher Intelligenz in  
                    den Sinn kommt. Häufig wird nämlich davon ausgegangen, dass Emotionen 
                    eine Angelegenheit sind, mit der nur Lebewesen etwas anfangen können. 
                    Doch genau diese Überzeugung gerät bei der Recherche über Affective 
                    Computing gewaltig ins Schwanken. Dieser Zweig der Informatik befasst 
                    sich nämlich genau damit, dass Künstliche Intelligenzen verschiedenste 
                    Zeichen von Gefühlen in einem Menschen feststellen und  
                    weiterverarbeiten können. <br>
                    Dieser Artikel beschäftigt sich damit, wie Affective Computing 
                    angewandt wird, funktioniert und sich auf unser Leben auswirkt. 
                    
                </p>
            </section>

            <section>
                <h2>Wann und warum wird Affective AI angwendet?</h2>
                <p>
                    Eine der häufigsten Anwendungen von Affective Computing liegt momentan in der Markt- und Kund*innenforschung grosser Unternehmen.
                    Als Evaluationswerkzeug von ihren Produkten benutzen Firmen wie Disney oder Kellog's Emotions-KI, um die Reaktionen von Konsument*innen 
                    zu erfassen, aufzuzeichnen und zu analysieren.<br> Es ist hier sehr viel einfacher, mit künstlicher Intelligenz zu arbeiten, 
                    als ohne. Riesige Datenmengen müssen ausgewertet werden und nur eine KI kann in kurzer Zeit genügende Daten aufnehmen, um in den Reaktionen von 
                    Tausenden von Kund*innen Muster zu erlernen und wiederzuerkennen. Ausserdem wird in der KI-Forschung davon ausgegangen, dass zum Beispiel bei der Reaktion auf einen neuen Disney-Film 
                    oftmals die Körperwerte eindeutiger die Meinung sagen, als eine mündliche Meinungsäusserung.
                </p>
            </section> 

            <section>
                <p>
                    Eine weitere Anwendung von Affective Computing ist im Gesundheitssektor, wo künstliche Intelligenz in Zukunft 
                    vielleicht sogar Personal ersetzen und Patient*innen direkt im Alltag helfen kann. Die Computerwissenschaftlerin Rosalind Picard 
                    verfolgt die Idee, Menschen mit Autismus-Spektrums-Störungen mit Affective Computing 
                    zu unterstützen. In ihrer <a href="https://affect.media.mit.edu/pdfs/09.Picard-PhilTranRoyalSocB.pdf">Publikation
                    zu Affective Computing bei Autismus-Spektrums-Störungen</a> beschreibt Picard Wege, wie autistischen Menschen und 
                    ihren Mitmenschen mit Emotions-KI geholfen werden kann, Reizüberflutungen festzustellen und zu kommunizieren. 
                </p>
            </section>
            
            <section>
                <h2>Wie funktioniert Affective Computing?</h2>
                <p>
                    Mit verschiedenen Sensoren und Kameras werden Daten wie die Mimik, Muskelspannung, Körperhaltung, 
                    Hand- und Schultergesten, Sprachmuster, Herzfrequenz, Pupillenerweiterung und die Körpertemperatur 
                    des Subjekts aufgenommen. Die daraus resultierenden Unmengen an Informationen werden danach von 
                    der künstlichen Intelligenz analysiert und in einer Datenbank abgelegt. Um die Analyse durchführen zu können 
                    wird die KI mit Machine Learning ausgebildet. Dabei werden ihr riesige Mengen an Daten zugespiesen und 
                    sie lernt, Muster in den Körperwerten und der Mimik zu erkennen und ihnen Gefülszustände zuzuordnen.
                    <br> Die Resultate aus den Analysen der Reaktionen von Kund*innen können dann vom Unternehmen 
                    verwendet werden, um Produkte anzupassen und ein erfolgreicheres Geschäft zu ermöglichen. 

                </p>
            </section>
            <section>
                <h2>Welche Problematik besteht mit Emotions-KI?</h2>
                <p>
                    Ein Nachteil des Affective Computing ist, dass es auf einer <a href="https://www.paulekman.com/universal-emotions/">Theorie des Psychologen 
                    Paul Ekman </a> basiert, die in der Psychologie umstritten ist. Paul Eckman geht davon aus, dass es sieben 
                    Grundemotionen gibt, die auf der ganzen Welt mit der Mimik gleich ausgedrückt werden. Diese Theorie ist nicht 
                    ausreichend wissenschaftlich bewiesen, wesshalb viele Spezialist*innen der Emotions-KI kritisch gegenüberstehen. 
                    Beim Namen "Emotions-KI" liegt ein weiterer Nachteil. Nämlich kann diese Künstliche Intelligenz nie mit vollkommener
                    Sicherheit feststellen, welche Vorgänge im Gehirn einer Person ablaufen. Desshalb ist das Ergebniss der KI nicht immer
                    richtig und das kann zu Problemen führen, wenn Affective Computing eine grosse Bedeutung in unserer Welt zugeteilt wird. <br>
                    Eine Künstliche Intelligenz, die in einer felerhaften Welt erstellt wird, trägt manchmal leider auch einige ihrer Problematiken 
                    in sich mit. Es ist nämlich im Fall der emotionserkennenden KI häufig der Fall, dass ihr die
                    rassistischen Überzeugungen ihrer Programmierer*innen beigebracht werden. So kommen manche Affective Computing Systeme 
                    bei der Analyse von People of Color zu falschen Resultaten. Die Auswertung der Mimik einer POC kommt zum Beispiel oft fälschlicherweise  
                    zum Schluss, dass die Person "wütend" oder "genervt" ist, was direkt mit rassistischen Stereotypen zusammenhängt. Diese 
                    Vorurteile hat sich die KI natürlich nicht selbst ausgedacht, sondern beim Machine Learning eingetrichtert bekommen.
                </p>
            </section>
            <section>
                <h2>Wie wirkt sich diese Technik auf die Gesellschaft aus?</h2>
                <p>
                    Eine Zukunft ohne den verstärkten Einsatz von künstlicher Intelligenz ist äusserst unrealistisch. 
                    Auch Affective Computing im Speziellen wird warscheinlich vorallem in der Marktforschung eine immer grösser werdende Rolle 
                    spielen. Wenn Konzerne die Reaktionen ihrer 
                    Kund*innen vermehrt beobachten und analysieren können, passen sie ihr Angebot den Rückmeldungen an.
                    Dadurch werden Produkte auf den Markt kommen, die noch mehr unseren Wünschen entsprechen. Obwohl das 
                    grundsätzlich sehr gut klingt, habe ich mit dieser Vorstellung ein Problem. So wird Überkonsum nämlich noch mehr gefördert. Schon jetzt ist
                    scheinbar nichts auf der Welt mehr erstrebenswert, als mehr zu besitzen. Ob wir die Produkte wirklich brauchen, ist 
                    dabei nebensächlich. Dieses Konsumverhalten hat schlechte Auswirkungen auf die Umwelt. <br>
                    Selbstverständlich kommt die Auswirkung von Affective Computing auf unser Leben sehr darauf an, wie es angewendet wird.
                    In den USA wird KI genutzt, um die Warscheinlichkeit einer Wiederholungstat bei Straftätigen einzuschätzen und wie <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Propublica</a>
                    schreibt, werden dabei People of Color unberechtigt gefährlicher eingestuft als weisse Menschen. <br>
                    So lange wir Emotions-KI nicht die Macht über wichtige Entscheidungen in unserer Welt geben, sondern ihre Vorzüge 
                    in Bereichen wie zum Beispiel dem Gesundheitssektor nutzen, sehe ich darin viele Vorteile. Auch werden mit der Zeit 
                    Formen des Affective Computing erforscht und benutzt werden, die sich gut für den jeweiligen Gebrauch eignen, was 
                    uns das Leben durchaus erleichtern kann. Das wichtigste ist dabei, das Systeme von verschiedenen Seiten geprüft und hinterfragt 
                    werden. So können wir Problemen wie zum Beispiel Rassismus und Datenmissbrauch hoffentlich entgegenwirken, während wir von KI profitieren.
                </p>
            </section>
            <section>
                <h4>Ein Artikel von Ida Simon, Mai 2022</h4>
            </section>
            <section>
                <h2>Quellenangaben</h2>
                <h6>
                    <a href="https://www.cbc.ca/news/science/disney-ai-real-time-tracking-fvae-1.4233063">CBC News über Disney</a>
                    <br>
                    <a href="https://viso.ai/deep-learning/visual-emotion-ai-recognition/#:~:text=Emotion%20AI%2C%20also%20called%20Affective,to%20assess%20their%20emotional%20state">Viso-AI über Emotion-AI</a> 
                    <br>
                    <a href="https://www.forbes.com/sites/bernardmarr/2017/12/15/the-next-frontier-of-artificial-intelligence-building-machines-that-read-your-emotions/?sh=1447e0c8647a">Forbes über Marktforschung mit KI</a>
                    <br>
                    <a href="https://www.computerweekly.com/de/definition/Affective-Computing-Emotion-AI#:~:text=Affective%20Computing%2C%20auch%20bekannt%20als,um%20menschliche%20Emotionen%20zu%20messen.">Computer Weekly über Emotion-AI</a>
                    <br>
                    <a href="https://affect.media.mit.edu/pdfs/09.Picard-PhilTranRoyalSocB.pdf">Rosalind Picard über KI bei ASS</a>
                    <br>
                    <a href="https://www.paulekman.com/universal-emotions/">Paul Ekman</a>
                    <br>
                    <a href="https://netzpolitik.org/2021/emotionale-ki-berechnete-gefuehle/">Netzpolitik über gesellschaftliche Folgen</a>
                    <br>
                    <a href="https://www.aclu.org/news/privacy-technology/how-artificial-intelligence-can-deepen-racial-and-economic-inequities">ACLU über Rasissmus in KI-Technologie</a>
                    <br>
                    <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Propublica über Racial Bias in KI</a>
                    <br>
                </h6>
        
            </section>

        </main>
    </body>
</html>

